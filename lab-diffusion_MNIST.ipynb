{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c10af92b45b74ac",
   "metadata": {},
   "source": [
    "# Lab 5: Diffusion\n",
    "Welcome to COMSM0159 Advanced Visual AI (AVAI)!\n",
    "\n",
    "The goal of this labsheet is to provide an introduction to Diffusion Models based on the Week 5 lecture. By the end of this lab, you should be able to:\n",
    "1. Understand the architecture of Diffusion Probabilistic Models (DDPMs)\n",
    "2. Train a diffusion model on the MNIST datset to remove noise from images.\n",
    "3. Experiment with the challenge: Enhancing the DDPM Model for the MNSIT Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449447fbdba1682",
   "metadata": {},
   "source": [
    "### What is Diffusion Model?\n",
    "\n",
    "A diffusion model is a generative model that progressively adds noise to data and then learns to reverse this process to recover the original data. It is often used for tasks like image generation, where it learns to generate clear images by reversing the noise-adding process step by step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53fb27c",
   "metadata": {},
   "source": [
    "> NOTE: If you are using Google Colab, uncomment and run the code block below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d6c2b63d01d781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load github resource in Colab\n",
    "# !git clone https://github.com/UoB-CS-AVAI/Week5-Diffusion.git\n",
    "# !mv Week5-Diffusion/* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a6b11bed49b494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image, make_grid\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import time  # For tracking time\n",
    "\n",
    "# Set device\n",
    "print(torch.__version__, torch.version.cuda, torch.cuda.is_available())\n",
    "# For GPU (CUDA) or CPU\n",
    "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "# Or for ARM-based MacOS\n",
    "# device = torch.device('mps')  # Only applicable if running on a Mac with M1/M2 chip and PyTorch with MPS support"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65db2f49a8782e3",
   "metadata": {},
   "source": [
    "##### Model Hyperparameters\n",
    "- **img_size**: `(28, 28, 1)`  \n",
    "  The size of input images (height, width, channels). For MNIST, images are 28x28 pixels with a single channel (grayscale).\n",
    "- **timestep_embedding_dim**: `256`  \n",
    "  The dimensionality of the embeddings that represent the timesteps in the diffusion process.\n",
    "- **n_layers**: `8`  \n",
    "  The number of layers in the model, defining its depth.\n",
    "- **n_timesteps**: `1000`  \n",
    "  The number of timesteps in the diffusion process, representing the total steps for noise addition and denoising.\n",
    "- **beta_minmax**: `[1e-4, 2e-2]`  \n",
    "  Defines the range of noise scales (betas) used in the diffusion process, starting from `1e-4` to `2e-2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37bae45fca39edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'dataset': 'MNIST',\n",
    "    'img_size': (28, 28, 1),\n",
    "    'timestep_embedding_dim': 256,\n",
    "    'n_layers': 8,\n",
    "    'hidden_dim': 256,\n",
    "    'n_timesteps': 1000,\n",
    "    'beta_minmax': [1e-4, 2e-2],\n",
    "    'train_batch_size': 128,\n",
    "    'inference_batch_size': 64,\n",
    "    'lr': 5e-5,\n",
    "    'epochs': 10,\n",
    "    'seed': 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db82fa3babd493e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dims = [config['hidden_dim'] for _ in range(config['n_layers'])]\n",
    "torch.manual_seed(config['seed'])\n",
    "# `config['seed']` to ensure that the initialization of weights and other random processes are consistent across different runs. This helps in making the training process reproducible.\n",
    "np.random.seed(config['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6f03c5b32bb79d",
   "metadata": {},
   "source": [
    "### Step 1: Load Dataset and Create DataLoader\n",
    "You will load the MNIST dataset and create DataLoaders for training and testing.\n",
    "  - `train_dataset` loads the training data, and `test_dataset` loads the test data.\n",
    "  - `transform`: Applies a transformation to convert images into tensors using `transforms.Compose([transforms.ToTensor()])`.\n",
    "  - `kwargs`: Specifies additional settings like `num_workers=4` for parallel data loading and `pin_memory=True` for faster data transfer to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b0b1e625ec2a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and DataLoader\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "kwargs = {'num_workers': 4, 'pin_memory': True}\n",
    "train_dataset = MNIST('./data/', transform=transform, train=True, download=True)\n",
    "test_dataset = MNIST('./data/', transform=transform, train=False, download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=config['train_batch_size'], shuffle=True, **kwargs)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=config['inference_batch_size'], shuffle=False, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1692350d80d25428",
   "metadata": {},
   "source": [
    "### Step 2: Define our model: Denoising Diffusion Probabilistic Model (DDPM)\n",
    "##### Sinusoidal embedding for diffusion timestep\n",
    "  - `SinusoidalPosEmb(dim)`: Generates embeddings for time steps to help the model recognise the relative positions of each diffusion step.\n",
    "  - `dim`: Specifies the dimension of the embedding.\n",
    "  - `forward(x)`: Creates position-aware embeddings for a batch of time steps `x`.\n",
    "    - Uses `sin` and `cos` functions to encode time information.\n",
    "    - Helps the model understand how noise evolves over different time steps, aiding in effective denoising.\n",
    "  - This sinusoidal positional embedding is crucial in the diffusion model as it encodes information about the position or timestep into a format that the model can use to better understand the temporal structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5661babae50d0c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4629c8d84e4424ff",
   "metadata": {},
   "source": [
    "##### In this Lab, we use a simple stacked-convolution model with various dilations\n",
    "  - `class ConvBlock(nn.Conv2d)`: A 2D convolutional block for diffusion models, supporting activation, dropout, and normalization.\n",
    "  - `in_channels`, `out_channels`: Input and output channel sizes.\n",
    "  - `kernel_size`, `stride`, `padding`, `dilation`: Control the convolution's spatial properties.\n",
    "  - `forward(x, time_embedding=None, residual=False)`\n",
    "    - Adds `time_embedding` if `residual=True` to incorporate timestep info.\n",
    "  - This block helps the model adapt to different noise levels and time steps in the diffusion process.\n",
    "\n",
    "You can also try building your own model: \n",
    "\n",
    "*Note: In the original paper, diffusion timestep embedding was only applied to residual blocks of U-Net.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446361be0464fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Conv2d):\n",
    "    \"\"\"\n",
    "        Conv2D Block\n",
    "            Args:\n",
    "                x: (N, C_in, H, W)\n",
    "            Returns:\n",
    "                y: (N, C_out, H, W)\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, activation_fn=None, drop_rate=0.,\n",
    "                    stride=1, padding='same', dilation=1, groups=1, bias=True, gn=False, gn_groups=8):\n",
    "        \n",
    "        if padding == 'same':\n",
    "            padding = kernel_size // 2 * dilation\n",
    "\n",
    "        super(ConvBlock, self).__init__(in_channels, out_channels, kernel_size,\n",
    "                                            stride=stride, padding=padding, dilation=dilation,\n",
    "                                            groups=groups, bias=bias)\n",
    "\n",
    "        self.activation_fn = nn.SiLU() if activation_fn else None\n",
    "        self.group_norm = nn.GroupNorm(gn_groups, out_channels) if gn else None\n",
    "        \n",
    "    def forward(self, x, time_embedding=None, residual=False):\n",
    "        if residual:\n",
    "            x = x + time_embedding\n",
    "            y = x\n",
    "            x = super(ConvBlock, self).forward(x)\n",
    "            y = y + x\n",
    "        else:\n",
    "            y = super(ConvBlock, self).forward(x)\n",
    "        y = self.group_norm(y) if self.group_norm is not None else y\n",
    "        y = self.activation_fn(y) if self.activation_fn is not None else y\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e90b63e466a3ae",
   "metadata": {},
   "source": [
    "##### Define Denoiser\n",
    "  - `class Denoiser(nn.Module)`: A model that removes noise from images at different steps of the diffusion process.\n",
    "  - `image_resolution`: The size of input images `(H, W, C)`.\n",
    "  - `self.time_embedding`: Generates embeddings for the diffusion timestep using `SinusoidalPosEmb`.\n",
    "\n",
    "  - **`forward(perturbed_x, diffusion_timestep)`**:\n",
    "    - `perturbed_x`: The noisy input image.\n",
    "    - `diffusion_timestep`: The current time step of the noise removal process.\n",
    "  - `Output`: Returns a denoised image of the same shape as `perturbed_x`.\n",
    "  - This model leverages the time embeddings to adapt the denoising process at each timestep, effectively learning how to reduce noise as the diffusion process progresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a6d81dc7d84898",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Denoiser(nn.Module):\n",
    "    def __init__(self, image_resolution, hidden_dims=[256, 256], diffusion_time_embedding_dim = 256, n_times=1000):\n",
    "        super(Denoiser, self).__init__()\n",
    "        _, _, img_C = image_resolution\n",
    "        self.time_embedding = SinusoidalPosEmb(diffusion_time_embedding_dim)\n",
    "        self.in_project = ConvBlock(img_C, hidden_dims[0], kernel_size=7)\n",
    "        self.time_project = nn.Sequential(\n",
    "                                 ConvBlock(diffusion_time_embedding_dim, hidden_dims[0], kernel_size=1, activation_fn=True),\n",
    "                                 ConvBlock(hidden_dims[0], hidden_dims[0], kernel_size=1))\n",
    "        self.convs = nn.ModuleList([ConvBlock(in_channels=hidden_dims[0], out_channels=hidden_dims[0], kernel_size=3)])\n",
    "        for idx in range(1, len(hidden_dims)):\n",
    "            self.convs.append(ConvBlock(hidden_dims[idx-1], hidden_dims[idx], kernel_size=3, dilation=3**((idx-1)//2),\n",
    "                                                    activation_fn=True, gn=True, gn_groups=8))                                                     \n",
    "        self.out_project = ConvBlock(hidden_dims[-1], out_channels=img_C, kernel_size=3)    \n",
    "        \n",
    "    def forward(self, perturbed_x, diffusion_timestep):\n",
    "        y = perturbed_x\n",
    "        diffusion_embedding = self.time_embedding(diffusion_timestep)\n",
    "        diffusion_embedding = self.time_project(diffusion_embedding.unsqueeze(-1).unsqueeze(-2)) \n",
    "        y = self.in_project(y)\n",
    "        for i in range(len(self.convs)):\n",
    "            y = self.convs[i](y, diffusion_embedding, residual = True) \n",
    "        y = self.out_project(y)   \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40a5ebe63089e3",
   "metadata": {},
   "source": [
    "##### Define Gaussian Diffusion\n",
    "- `class Diffusion(nn.Module)`: Handles the diffusion process, both adding noise and removing it to generate clean images.\n",
    "- `n_times`: Number of diffusion steps.\n",
    "- `betas`: Controls how much noise is added at each step.\n",
    "- `alphas`: Derived from `betas`, used for noise removal.\n",
    "\n",
    "    - `make_noisy(x_zeros, t)`: Adds noise to images at a given step `t`, simulating the forward process.\n",
    "    - `forward(x_zeros)`: Adds noise to images and predicts the noise using the model.\n",
    "    - `denoise_at_t(x_t, timestep)`: Uses the model to remove noise at a specific step.\n",
    "    - `sample(N)`: Generates new images by starting with noise and denoising step-by-step.\n",
    "\n",
    "  - This class models the forward and reverse processes of diffusion, adding noise progressively and then removing it to generate new images from pure noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac143f887d85f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Diffusion(nn.Module):\n",
    "    def __init__(self, model, image_resolution=[28, 28, 1], n_times=1000, beta_minmax=[1e-4, 2e-2], device='cuda'):\n",
    "        super(Diffusion, self).__init__()\n",
    "        self.n_times = n_times\n",
    "        self.img_H, self.img_W, self.img_C = image_resolution\n",
    "        self.model = model\n",
    "        # Define linear variance schedule (betas)\n",
    "        beta_1, beta_T = beta_minmax\n",
    "        betas = torch.linspace(start=beta_1, end=beta_T, steps=n_times).to(device) # follows DDPM paper: cosine function instead of linear?\n",
    "        self.sqrt_betas = torch.sqrt(betas)                             \n",
    "        # Define alphas for forward diffusion process\n",
    "        self.alphas = 1 - betas\n",
    "        self.sqrt_alphas = torch.sqrt(self.alphas)\n",
    "        alpha_bars = torch.cumprod(self.alphas, dim=0)\n",
    "        self.sqrt_one_minus_alpha_bars = torch.sqrt(1-alpha_bars)\n",
    "        self.sqrt_alpha_bars = torch.sqrt(alpha_bars)\n",
    "        self.device = device\n",
    "    \n",
    "    def extract(self, a, t, x_shape):\n",
    "        # Extract the specific values for the batch of time-steps `t`\n",
    "        b, *_ = t.shape\n",
    "        out = a.gather(-1, t)\n",
    "        return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
    "    \n",
    "    def scale_to_minus_one_to_one(self, x):\n",
    "        # Scale input `x` from [0, 1] to [-1, 1]\n",
    "        return x * 2 - 1\n",
    "    \n",
    "    def reverse_scale_to_zero_to_one(self, x):\n",
    "        # Scale input `x` from [-1, 1] back to [0, 1]\n",
    "        return (x + 1) * 0.5\n",
    "    \n",
    "    def make_noisy(self, x_zeros, t): \n",
    "        # Perturb `x_0` into `x_t` (forward diffusion process)\n",
    "        epsilon = torch.randn_like(x_zeros).to(self.device)\n",
    "        sqrt_alpha_bar = self.extract(self.sqrt_alpha_bars, t, x_zeros.shape)\n",
    "        sqrt_one_minus_alpha_bar = self.extract(self.sqrt_one_minus_alpha_bars, t, x_zeros.shape)\n",
    "        # Let's make noisy sample!: i.e., Forward process with fixed variance schedule\n",
    "        #      i.e., sqrt(alpha_bar_t) * x_zero + sqrt(1-alpha_bar_t) * epsilon\n",
    "        noisy_sample = x_zeros * sqrt_alpha_bar + epsilon * sqrt_one_minus_alpha_bar\n",
    "        return noisy_sample.detach(), epsilon\n",
    "    \n",
    "    \n",
    "    def forward(self, x_zeros):\n",
    "        x_zeros = self.scale_to_minus_one_to_one(x_zeros)\n",
    "        B, _, _, _ = x_zeros.shape\n",
    "        # 1. Randomly select a diffusion time-step `t`\n",
    "        t = torch.randint(low=0, high=self.n_times, size=(B,)).long().to(self.device)\n",
    "        # 2. Forward diffusion: perturb `x_zeros` using the fixed variance schedule\n",
    "        perturbed_images, epsilon = self.make_noisy(x_zeros, t)\n",
    "        # 3. Predict the noise (`epsilon`) given the perturbed image at time-step `t`\n",
    "        pred_epsilon = self.model(perturbed_images, t)\n",
    "        return perturbed_images, epsilon, pred_epsilon\n",
    "    \n",
    "    \n",
    "    def denoise_at_t(self, x_t, timestep, t):\n",
    "        B, _, _, _ = x_t.shape\n",
    "        # Generate random noise `z` for sampling, except for the final step (`t=0`)\n",
    "        if t > 1:\n",
    "            z = torch.randn_like(x_t).to(self.device)\n",
    "        else:\n",
    "            z = torch.zeros_like(x_t).to(self.device)\n",
    "        # at inference, we use predicted noise(epsilon) to restore perturbed data sample.\n",
    "        # Use the model to predict noise (`epsilon_pred`) given `x_t` at `timestep`\n",
    "        epsilon_pred = self.model(x_t, timestep)\n",
    "        alpha = self.extract(self.alphas, timestep, x_t.shape)\n",
    "        sqrt_alpha = self.extract(self.sqrt_alphas, timestep, x_t.shape)\n",
    "        sqrt_one_minus_alpha_bar = self.extract(self.sqrt_one_minus_alpha_bars, timestep, x_t.shape)\n",
    "        sqrt_beta = self.extract(self.sqrt_betas, timestep, x_t.shape)\n",
    "        # denoise at time t, denoise `x_t` to estimate `x_{t-1}`\n",
    "        x_t_minus_1 = 1 / sqrt_alpha * (x_t - (1-alpha)/sqrt_one_minus_alpha_bar*epsilon_pred) + sqrt_beta*z\n",
    "        return x_t_minus_1.clamp(-1., 1)\n",
    "                \n",
    "    def sample(self, N):\n",
    "        # Start from random noise vector `x_T`, x_0 (for simplicity, x_T declared as x_t instead of x_T)\n",
    "        x_t = torch.randn((N, self.img_C, self.img_H, self.img_W)).to(self.device)\n",
    "        # Autoregressively denoise from `x_T` to `x_0`\n",
    "        #     i.e., generate image from noise, x_T\n",
    "        for t in range(self.n_times-1, -1, -1):\n",
    "            timestep = torch.tensor([t]).repeat_interleave(N, dim=0).long().to(self.device)\n",
    "            x_t = self.denoise_at_t(x_t, timestep, t)\n",
    "        # Convert the final result `x_0` back to [0, 1] range\n",
    "        x_0 = self.reverse_scale_to_zero_to_one(x_t)\n",
    "        return x_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fb6630b9021cb6",
   "metadata": {},
   "source": [
    "### Step 3: Initialise DDPM Model and optimizer\n",
    "#### Task 1: Initialise DDPM Model and Optimizer\n",
    "  - **`model`**: Creates a `Denoiser` using settings from `config` and moves it to `DEVICE`.\n",
    "  - **`diffusion`**: Wraps the `model` to manage noise processes.\n",
    "  - **`optimizer`**: Adam optimizer with learning rate from .\n",
    "  - This setup gets the model ready for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9e6d2939597723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Initialise Model and optimizer\n",
    "model = \n",
    "diffusion = \n",
    "optimizer = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4a080199b5398c",
   "metadata": {},
   "source": [
    "#### Task 2: Visualising forward process\n",
    "\n",
    "- Display a specific image (idx) from a batch (x) to visually assess how the noise affects it at a given timestep.\n",
    "- TODO: Generate and display images at different timesteps to show how noise progressively increases during the diffusion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a4133eb4dc805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays the image at `idx` from batch `x`\n",
    "def show_image(x, idx):\n",
    "    fig = plt.figure()\n",
    "    image_data = x[idx].transpose(0, 1).transpose(1, 2).detach().cpu().numpy()\n",
    "    image_data = np.clip(image_data, 0, 1)\n",
    "    plt.imshow(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69485da879249613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Generate and display images at different timesteps\n",
    "def visualise_forward_process_by_t(diffusion, x, num_timesteps_to_show):\n",
    "    x = diffusion.scale_to_minus_one_to_one(x)\n",
    "    timesteps = \n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c64afc0e052f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "for batch_idx, (x, _) in enumerate(test_loader):\n",
    "    x = x.to(DEVICE)\n",
    "    perturbed_images, epsilon, pred_epsilon = diffusion(x)\n",
    "    perturbed_images = diffusion.reverse_scale_to_zero_to_one(perturbed_images)\n",
    "    # TODO: Generate and display images at different timesteps\n",
    "    # TODO: visualise_forward_process_by_t()\n",
    "    break\n",
    "\n",
    "# Show the perturbed image\n",
    "show_image(perturbed_images, idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eea8078a81afff",
   "metadata": {},
   "source": [
    "### Step 4: Define the Train Loop - Train Denoising Diffusion Probabilistic Models (DDPMs)\n",
    "#### Task 3: Train the diffusion model using MNIST data\n",
    "    - `diffusion.train()`: Set the model to training mode.\n",
    "    - `denoising_loss`: Uses Mean Squared Error (MSE) loss to measure the difference between the predicted and actual noise.\n",
    "    - **Training Loop**: For each batch\n",
    "        - Adds noise to images.\n",
    "        - Predicts noise and computes the loss.\n",
    "        - Updates model parameters using `optimizer`.\n",
    "        - Displays the average loss.\n",
    "    - `noisy_input, epsilon, pred_epsilon = diffusion(x)`: Generates noisy images and predicts the noise.\n",
    "    - `loss = denoising_loss(pred_epsilon, epsilon)`: Calculates the loss between the predicted noise and true noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "428b89f8aef0b5d",
   "metadata": {},
   "source": [
    "#### Task 4: Measure and compare the training time with the inference time of the model, then analyse and discuss the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb316dce6c3f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(diffusion, train_loader, optimizer, epochs, device):\n",
    "    # TODO: Set model to train mode\n",
    "    \n",
    "    # Initialise gradient scaler for mixed precision training\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    # TODO: Define loss function (Mean Squared Error Loss)\n",
    "    \n",
    "    total_train_time = 0\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        total_loss = 0.0\n",
    "        for batch_idx, (x, _) in enumerate(train_loader):\n",
    "            # Clear previous gradients\n",
    "            optimizer.zero_grad()\n",
    "            x = x.to(device)\n",
    "            \n",
    "            # Forward pass with mixed precision\n",
    "            # - **Mixed Precision**: `torch.cuda.amp.autocast()` enables faster training with less memory usage.\n",
    "            with torch.cuda.amp.autocast():\n",
    "                # TODO: Call the diffusion model to get noisy input\n",
    "                \n",
    "                # TODO: Calculate the denoising loss\n",
    "\n",
    "            # Use the scaler to scale the loss and backpropagate\n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "            # TODO: Update the model parameters using the optimizer\n",
    "            \n",
    "            # TODO: Update the scaler for the next iteration\n",
    "            \n",
    "            # TODO: Accumulate the loss\n",
    "\n",
    "        # TODO: Print the average loss for this epoch\n",
    "        print(f\"Epoch [{epoch + 1}/{epochs}], Loss: {avg_loss:.6f}\")\n",
    "        # TODO: Print the training time for this epoch\n",
    "\n",
    "    print(\"Training finished!\")\n",
    "    print(f\"Total training time: {total_train_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5044a6d4c4195f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Training - Try more epochs and see what happens\n",
    "print(\"Start training DDPMs...\")\n",
    "train(diffusion, train_loader, optimizer, config['epochs'], DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6513c7efcfbb10db",
   "metadata": {},
   "source": [
    "### Step 5: Sample images from noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01195d17316c20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_sample_image(x, postfix):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Visualisation of {postfix}\")\n",
    "    plt.imshow(np.transpose(make_grid(x.detach().cpu(), padding=2, normalize=True), (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a354f62dbe20676",
   "metadata": {},
   "source": [
    "#### Task 5: Evaluation and Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7432f94925c18ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Evaluation and Sampling\n",
    "# TODO: Set model to evaluation mode\n",
    "# TODO: Measure inference time\n",
    "show_image(generated_images, idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74f0f036a784255",
   "metadata": {},
   "source": [
    "#### Task 6: Comparison with ground-truth samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26dabee8356e9b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Visualisation\n",
    "# Display a sample of noisy images\n",
    "# Display images generated by the model\n",
    "# Display a sample of original images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20a3d559c501e94",
   "metadata": {},
   "source": [
    "### Challenge: Enhancing the DDPM Model for the MNSIT Dataset\n",
    "\n",
    "- Use the same network structure. You need to experiment with different parameters and loss functions to optimise the performance of the model.\n",
    "\n",
    "#### Task 1: Parameter Tuning\n",
    "- Training epochs: Change the number of training epochs that the model needs to efficiently learn the diffusion process.\n",
    "\n",
    "- Timesteps: Try using different timesteps in the diffusion process to see how they affect the quality of the noised image and denoised images.\n",
    "\n",
    "- Beta schedule: Modify the beta values used in the diffusion process to improve image generation.\n",
    "\n",
    "#### Task 2: Add noise using a cosine schedule instead of a linear schedule \n",
    "- Reference: https://arxiv.org/abs/2102.09672\n",
    "\n",
    "#### Task 3: Loss Functions\n",
    "- Explore alternatives to MSE: e.g. MAE, SSIM, LPIPS.\n",
    "- SSIM better captures perceptual and structural similarities in images. Test in combination with different losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ca5a18c342103",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from model.Denoiser import Denoiser\n",
    "from model.utils import show_image, draw_sample_image, visualise_forward_process_by_t\n",
    "\n",
    "\n",
    "class Diffusion(nn.Module):\n",
    "    def __init__(self, model, image_resolution=[28, 28, 1], n_times=1000, beta_minmax=[1e-4, 2e-2], device='cuda'):\n",
    "        super(Diffusion, self).__init__()\n",
    "        self.n_times = n_times\n",
    "        self.img_H, self.img_W, self.img_C = image_resolution\n",
    "        self.model = model\n",
    "        beta_1, beta_T = beta_minmax\n",
    "        betas = torch.linspace(start=beta_1, end=beta_T, steps=n_times).to(device)\n",
    "        self.sqrt_betas = torch.sqrt(betas)\n",
    "        self.alphas = 1 - betas\n",
    "        self.sqrt_alphas = torch.sqrt(self.alphas)\n",
    "        alpha_bars = torch.cumprod(self.alphas, dim=0)\n",
    "        self.sqrt_one_minus_alpha_bars = torch.sqrt(1 - alpha_bars)\n",
    "        self.sqrt_alpha_bars = torch.sqrt(alpha_bars)\n",
    "        self.device = device\n",
    "\n",
    "    def extract(self, a, t, x_shape):\n",
    "        b, *_ = t.shape\n",
    "        out = a.gather(-1, t)\n",
    "        return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
    "\n",
    "    def scale_to_minus_one_to_one(self, x):\n",
    "        return x * 2 - 1\n",
    "\n",
    "    def reverse_scale_to_zero_to_one(self, x):\n",
    "        return (x + 1) * 0.5\n",
    "\n",
    "    def make_noisy(self, x_zeros, t):\n",
    "        epsilon = torch.randn_like(x_zeros).to(self.device)\n",
    "        sqrt_alpha_bar = self.extract(self.sqrt_alpha_bars, t, x_zeros.shape)\n",
    "        sqrt_one_minus_alpha_bar = self.extract(self.sqrt_one_minus_alpha_bars, t, x_zeros.shape)\n",
    "        noisy_sample = x_zeros * sqrt_alpha_bar + epsilon * sqrt_one_minus_alpha_bar\n",
    "        return noisy_sample.detach(), epsilon\n",
    "\n",
    "    def forward(self, x_zeros):\n",
    "        x_zeros = self.scale_to_minus_one_to_one(x_zeros)\n",
    "        B, _, _, _ = x_zeros.shape\n",
    "        t = torch.randint(low=0, high=self.n_times, size=(B,)).long().to(self.device)\n",
    "        perturbed_images, epsilon = self.make_noisy(x_zeros, t)\n",
    "        pred_epsilon = self.model(perturbed_images, t)\n",
    "        return perturbed_images, epsilon, pred_epsilon\n",
    "\n",
    "    def denoise_at_t(self, x_t, timestep, t):\n",
    "        B, _, _, _ = x_t.shape\n",
    "        if t > 1:\n",
    "            z = torch.randn_like(x_t).to(self.device)\n",
    "        else:\n",
    "            z = torch.zeros_like(x_t).to(self.device)\n",
    "        epsilon_pred = self.model(x_t, timestep)\n",
    "        alpha = self.extract(self.alphas, timestep, x_t.shape)\n",
    "        sqrt_alpha = self.extract(self.sqrt_alphas, timestep, x_t.shape)\n",
    "        sqrt_one_minus_alpha_bar = self.extract(self.sqrt_one_minus_alpha_bars, timestep, x_t.shape)\n",
    "        sqrt_beta = self.extract(self.sqrt_betas, timestep, x_t.shape)\n",
    "        x_t_minus_1 = 1 / sqrt_alpha * (x_t - (1 - alpha) / sqrt_one_minus_alpha_bar * epsilon_pred) + sqrt_beta * z\n",
    "        return x_t_minus_1.clamp(-1., 1)\n",
    "\n",
    "    def sample(self, N):\n",
    "        x_t = torch.randn((N, self.img_C, self.img_H, self.img_W)).to(self.device)\n",
    "        for t in range(self.n_times - 1, -1, -1):\n",
    "            timestep = torch.tensor([t]).repeat_interleave(N, dim=0).long().to(self.device)\n",
    "            x_t = self.denoise_at_t(x_t, timestep, t)\n",
    "        x_0 = self.reverse_scale_to_zero_to_one(x_t)\n",
    "        return x_0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
